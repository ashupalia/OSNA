{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For State Chicago-classify.csv total number of tweets: 100\n",
      "Total positive tweets:46\n",
      "Total negative tweets:54\n",
      "More negative tweets in the city of Chicago-classify.csv\n",
      "For State London-classify.csv total number of tweets: 100\n",
      "Total positive tweets:23\n",
      "Total negative tweets:77\n",
      "More negative tweets in the city of London-classify.csv\n",
      "For State Sydney-classify.csv total number of tweets: 100\n",
      "Total positive tweets:47\n",
      "Total negative tweets:53\n",
      "More negative tweets in the city of Sydney-classify.csv\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter, defaultdict\n",
    "from itertools import chain, combinations\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "##################################################################################################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~This function tokenizes the text~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "##################################################################################################\n",
    "\n",
    "def tokenize(docs, keep_internal_punct=False):\n",
    "    doc=str(docs)\n",
    "    l= doc.lower()\n",
    "    l1=[]\n",
    "    if  not keep_internal_punct :\n",
    "        l1=re.sub(\"\\W+\",' ',l).split()\n",
    "    else:\n",
    "        for x in l.split():\n",
    "            l1.append(x.strip(string.punctuation))\n",
    "    return np.array([d.lower() for d in l1 if len(d)>=3])\n",
    "\n",
    "##################################################################################################\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~This function creates a csr matrix~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "##################################################################################################\n",
    "def create_csv(vocab,x,qr):\n",
    "    global wordlist\n",
    "    r=list()\n",
    "    c=list()\n",
    "    d=list()\n",
    "    i=0\n",
    "    pt = \"newJ\"\n",
    "    for l in x:\n",
    "        wordlist=nltk.FreqDist(l)\n",
    "        for a,b in wordlist.items():\n",
    "            if a in vocab.keys():\n",
    "                d.append(b)\n",
    "                r.append(i)\n",
    "                c.append(vocab[a])\n",
    "        i=i+1\n",
    "    #print(wordlist)\n",
    "    val = len(vocab.keys())\n",
    "    data=np.array(d)\n",
    "    row=np.array(r)\n",
    "    col=np.array(c)\n",
    "    return csr_matrix((data,(row,col)),shape=(i,val))\n",
    "\n",
    "############################################################################################################\n",
    "#~~~~~~~This function classify a tweet as a positive, negative or neutral using sentiment analysis~~~~~~~~~#\n",
    "############################################################################################################\n",
    "def classify():\n",
    "    data=['Chicago-classify.csv','London-classify.csv','Sydney-classify.csv']\n",
    "    city_name = ['Chicago', 'London','Sydney']\n",
    "    x=list()\n",
    "    y=list()\n",
    "    qr = 0\n",
    "    labels=list()\n",
    "    \n",
    "    file1 = open('classify.txt', 'w+')\n",
    "    ps=pd.read_csv(\"pos.csv\",sep='\\t')\n",
    "    tweets=ps['tweets'].tolist()\n",
    "    twee = 0\n",
    "    for t in tweets:\n",
    "        l=list(tokenize(t))\n",
    "        x.extend(l)\n",
    "    for t in tweets:\n",
    "        l=list(tokenize(t))\n",
    "        y.append(l)\n",
    "        twee = twee+1\n",
    "    for i in range(twee):\n",
    "        labels.append(1)\n",
    "\n",
    "    ns=pd.read_csv(\"neg.csv\",sep='\\t')\n",
    "    \n",
    "    tweetsn=ns['tweets'].tolist()\n",
    "    pwee = 0\n",
    "    for t in tweetsn:\n",
    "        l=list(tokenize(t))\n",
    "        x.extend(l)\n",
    "    for t in tweetsn:\n",
    "        l=list(tokenize(t))\n",
    "        y.append(l)\n",
    "        pwee = pwee + 1\n",
    "    for i in range(pwee):\n",
    "        labels.append(0)\n",
    "    \n",
    "    wordlist=nltk.FreqDist(x)\n",
    "    vocab=dict()\n",
    "    min_freq=2\n",
    "    i=0\n",
    "    \n",
    "    for key,values in wordlist.items():\n",
    "        if values>=min_freq:\n",
    "            vocab[key]=i\n",
    "            i+=1\n",
    "    X=create_csv(vocab,y,qr)\n",
    "    clf=LogisticRegression()\n",
    "    clf.fit(X.toarray(),labels)\n",
    "    posv=0\n",
    "    negv=0\n",
    "    flag=0\n",
    "    for name in data:\n",
    "        y=[]\n",
    "        ns=pd.read_csv(name,sep='\\t')\n",
    "        tweetsn=ns['text'].tolist()\n",
    "        for t in tweetsn:\n",
    "            l=list(tokenize(t))\n",
    "            y.append(l)\n",
    "        \n",
    "        X=create_csv(vocab,y,qr)\n",
    "        lb=clf.predict(X.toarray())\n",
    "        lab=list(lb)\n",
    "        at = str(len(lb))\n",
    "        print(\"For State \"+name+\" total number of tweets: \"+at)\n",
    "        positive_count = str(lab.count(1))\n",
    "        negative_count = str(lab.count(0)) \n",
    "        print(\"Total positive tweets:\"+positive_count)\n",
    "        print(\"Total negative tweets:\"+negative_count)\n",
    "        if positive_count > negative_count:\n",
    "            print(\"More positive tweets i.e. \"+ positive_count + \" in the city of \" + name)\n",
    "        else:\n",
    "            print(\"More negative tweets in the city of \"+name)\n",
    "        \n",
    "        \n",
    "        count_one = lab.count(1)\n",
    "        count_zero = lab.count(0)\n",
    "        posv=posv+count_one\n",
    "        negv=negv+count_zero\n",
    "        pt=tweetsn[lab.index(1)]\n",
    "        nt=tweetsn[lab.index(0)]\n",
    "    if file1.mode == 'w+':\n",
    "        file1.write(\"Total number of positive tweets:\"+str(posv)+\"\\nExample of a positive tweet is \\n\"+pt)\n",
    "        file1.write(\"\\nTotal number of negative tweets:\"+str(negv)+\"\\nExample of a negative tweet is \\n\"+nt)\n",
    "        file1.close()\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \"\"\" Main method. You should not modify this. \"\"\"\n",
    "    newt = 0\n",
    "    classify()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
